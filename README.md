# ScraperProject
How To Run-

To run this application you should have installed Python 3.6, Scrapy python package manager as Anaconda and PyCharm.
Import project in PyCharm and run spider as BuildIt_Scraper on console you can see all result.
Second way open anaconda command prompt go to the project directory as BuildIt_Scrapper and run below command
           scrapy crawl datablogger -o buildit.csv -t csv-------To save all result in csv file
           scrapy crawl datablogger -o buildit.json -t json-----To save all result in jason format.
To run as service you have to deploy on some cloud or scrapy cloud and run below url
           [deploy]
           #url = http://localhost:6800/

TradeOff--

we can develop this webcrawler in other language too like bootstrap and java but Python has set of rich module and framework to remove boilerplate code and we can only concentrate on spider then other stuff.

What could be done-

I have completed all testcase as given in assignment but i can do more like production ready project to use selector XML Selector and CSS path and Beautiful Soup.
I can extract all required data in better way and can store in DataBase then our need we can use it.
